{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the code for a simple multylayer perceptron network. It is trained on MNIST handwritten digits data-set. Then single digit from a data-set is used to provide clear probabilites for its recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Baseline MLP for MNIST dataset\n",
    "import numpy\n",
    "import skimage.io as io \n",
    "import os \n",
    "import platform\n",
    "import getpass\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load data\n",
    "platform = platform.system()\n",
    "currentUser = getpass.getuser()\n",
    "currentDirectory = os.getcwd()\n",
    "\n",
    "if platform is 'Windows':\n",
    "\t#path_image = 'C:\\\\Users\\\\' + currentUser\n",
    "\tpath_image = currentDirectory \n",
    "else:\t\n",
    "\t#path_image = '/user/' + currentUser\n",
    "\tpath_image = currentDirectory \n",
    "fn = 'image.png'\n",
    "img = io.imread(os.path.join(path_image, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (60000, 784))\n",
      "('X_t shape:', (1, 784))\n",
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n",
      "(1, 'test images')\n",
      "(10, 'number of classes')\n"
     ]
    }
   ],
   "source": [
    "# prepare arrays\n",
    "X_t = []\n",
    "y_t = []\n",
    "X_t.append(img)\n",
    "y_t.append(3)\n",
    "\n",
    "X_t = numpy.asarray(X_t)\n",
    "y_t = numpy.asarray(y_t)\n",
    "y_t = np_utils.to_categorical(y_t, 10)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "X_t = X_t.reshape(X_t.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_t /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print ('X_t shape:', X_t.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print(X_t.shape[0], 'test images')\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(y_test.shape[1], 'number of classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, init='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\t\n",
    "def build_model(model):\n",
    "\t# build the model\n",
    "    model = baseline_model()\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "    return model\n",
    "\n",
    "def save_model(model):\n",
    "\t# serialize model to JSON\n",
    "\tmodel_json = model.to_json()\n",
    "\twith open(\"model.json\", \"w\") as json_file:\n",
    "\t\tjson_file.write(model_json)\n",
    "\t# serialize weights to HDF5\n",
    "\tmodel.save_weights(\"model.h5\")\n",
    "\tprint(\"Saved model to disk\")\n",
    "\t\n",
    "def load_model():\n",
    "\t# load json and create model\n",
    "\tjson_file = open('model.json', 'r')\n",
    "\tloaded_model_json = json_file.read()\n",
    "\tjson_file.close()\n",
    "\tloaded_model = model_from_json(loaded_model_json)\n",
    "\t# load weights into new model\n",
    "\tloaded_model.load_weights(\"model.h5\")\n",
    "\tif loaded_model:\n",
    "\t\tprint(\"Loaded model\")\n",
    "\telse:\n",
    "\t\tprint(\"Model is not loaded correctly\")\n",
    "\treturn loaded_model\n",
    "\n",
    "def print_class(scores):\n",
    "\tfor index, score in numpy.ndenumerate(scores):\n",
    "\t\tnumber = index[1]\n",
    "\t\tprint (number, \"-\", score)\n",
    "\tfor index, score in numpy.ndenumerate(scores):\n",
    "\t\tif(score > 0.5):\n",
    "\t\t\tnumber = index[1]\n",
    "\t\t\tprint (\"\\nNumber is: %d, probability is: %f\" % (number, score))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n",
      "Probabilities for each class\n",
      "\n",
      "(0, '-', 3.4988901e-07)\n",
      "(1, '-', 3.7538914e-08)\n",
      "(2, '-', 0.00072528532)\n",
      "(3, '-', 0.99788445)\n",
      "(4, '-', 1.7879113e-08)\n",
      "(5, '-', 1.3890726e-06)\n",
      "(6, '-', 2.5650074e-10)\n",
      "(7, '-', 2.233218e-05)\n",
      "(8, '-', 0.0012537371)\n",
      "(9, '-', 0.00011237688)\n",
      "\n",
      "Number is: 3, probability is: 0.997884\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "path = os.path.exists(\"model.json\")\n",
    "\t\n",
    "if not path:\n",
    "\tmodel = build_model(model)\n",
    "\tsave_model(model)\n",
    "\t# Final evaluation of the model\n",
    "\tscores = model.predict(X_t)\n",
    "\tprint(\"Probabilities for each class\\n\")\n",
    "\tprint_class(scores)\n",
    "else:\n",
    "\t# Final evaluation of the model\n",
    "\tloaded_model = load_model()\n",
    "\tif loaded_model is not None:\n",
    "\t\tloaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\t\tscores = loaded_model.predict(X_t)\n",
    "\t\tprint(\"Probabilities for each class\\n\")\n",
    "\t\tprint_class(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
